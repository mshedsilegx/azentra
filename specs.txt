1- Implement the logic below from powershell

Write-Host "Extraction of azureadgroupmembers is started"
    Try{
        $adgrouplist = @()
        $adgrouplist = az ad group list --query [*].[displayName] --output tsv
        $adgrouplistcount = $adgrouplist.Count 
        Write-Output "[" | out-file -Append -encoding unicode -filepath "adgroupmembers.json"
        foreach($adgrp in $adgrouplist)
        {
	        Write-Host "Data extraction for group $adgrp"
            Write-Output "{" | out-file -Append -encoding unicode -filepath "adgroupmembers.json"
            Write-Output """ADGroupName"":""$adgrp""" | out-file -Append -encoding unicode -filepath "adgroupmembers.json"
	
	        $cnt8=az ad group member list --group $adgrp --output tsv
	        if ($cnt8.count -ne 0)
	        {
	        Write-Output ",""ADGroupMemberName"":" | out-file -Append -encoding unicode -filepath "adgroupmembers.json"
            az ad group member list --group $adgrp --output json | out-file -Append -encoding unicode -filepath "adgroupmembers.json"
	        }
            $adgrouplistcount=$adgrouplistcount-1
            If($adgrouplistcount -ge 1){
                Write-Output "}," | out-file -Append -encoding unicode -filepath "adgroupmembers.json"
                }
                Else{   
                Write-Output "}" | out-file -Append -encoding unicode -filepath "adgroupmembers.json"
                }
        }
        Write-Output "]" | out-file -Append -encoding unicode -filepath "adgroupmembers.json"
    }
    catch{
      Write-Output "Issue with GroupMembers Listing" | out-file -encoding unicode -filepath "adgroupmembers.json"
    }
	

2- Respect the generic rules below:
2.1- run go get -u ./..., go mod tidy, go fmt ./... go vet ./... before committing. Do not build nor submit to github repo without approval.
2.2- always optimize for performance by parallelizing as much as possible, and a very large number of objects
2.3- Make sure are we not flooding the API with requests, and than a retry mechanism with exponential backoff is implemented to address any transient errors. Both would have best practice values.
2.4- Only use well maintained, safe and production ready golang modules. Limit the use of third party libraries if possible, always prefer core libs.
2.5- perform a code review for security, performance and modularity, and provide recommendations. Initiate memory recording.
2.6- Make sure all inputs are sanitized.

3- Application features
3.1- Make the output json file location and name an argument. It defauls as: adgroupmembers.json in the current folder.
3.2- Produce also a sqlite (use pure golang driver, no C dependencies) file called <entra_tenant_id>_YYYYMMDD-hhmmss.db with the following table name entraGroups.
     field structure
     ----------+-------------
     groupName | groupMember
     ----------+-------------
     and include indexes to optimize query:
     select groupName from entraGroups where groupMember like "<name_of_member>%" where 
     and 
     select groupmember from entraGroups where groupName like "<name_of_group>%"

3.3- generate both json file (with a streaming encoder, with explicit write buffering) and sqlite db in parallel, to minimize memory usage
     For sqlite inserts, implement a large transaction commit for bulk inserts, disable synchronous writes, and use prepared statements.
3.4- Implement an option to filter groups via regexp, instead of considering them all
3.5- Add total number of groups to process, and for each group a percentage of completion
3.6- group name and member can contain non alphabet/digit characters, make sure that will not cause escaping issues
